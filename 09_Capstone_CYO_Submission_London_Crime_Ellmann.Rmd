---
title: "HarvardX Data Science Capstone Project"
subtitle: "London Crime Prediction"
author: "*Erdmuthe Ellmann*"
date: "*May 31st 2020*"
output: 
  pdf_document:
    toc: true 
    toc_depth: 3  
    number_sections: true
    highlight: haddock
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, text.align='justify', fig.align='center', cache=FALSE, cache.lazy=FALSE)
```


```{r, include=FALSE, echo=FALSE}
# install packages if needed
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org") 
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(ggrepel)) install.packages("ggrepel", repos = "http://cran.us.r-project.org")
if(!require(forecast)) install.packages("forecast", repos = "http://cran.us.r-project.org")
if(!require(broom)) install.packages("broom", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")

# load libraries
library(tidyverse)
library(caret)
library(data.table)
library(ggplot2)
library(lubridate)
library(ggrepel)
library(forecast)
library(broom)
library(rpart)
library(kableExtra)

# disable scientific notation
options(scipen = 999)      

```



```{r include=FALSE, echo=FALSE}
# download the data from github

# The two files are in a subfolder "/data" and have to be downloaded and unzipped

# download each file from github
dl <- tempfile()
download.file("https://github.com/ellmanne/LondonCrime/raw/master/data/londoncrime2016.zip", dl)
londoncrime2016_csv <- unzip(dl, "londoncrime2016.csv")
londoncrime_temp <- read.csv(londoncrime2016_csv, stringsAsFactors = FALSE)

dl <- tempfile()
download.file("https://github.com/ellmanne/LondonCrime/raw/master/data/london-boroughs.zip", dl)
londonboroughs_csv <- unzip(dl, "london-borough-profiles-2016 Data set.csv")
londonboroughs_temp <- read.csv(londonboroughs_csv, stringsAsFactors = FALSE)

# remove the files that are not needed anymore
rm(londoncrime2016_csv, londonboroughs_csv)
```

\newpage

# Introduction

This project is part of the ninth and final course in HarvardX's multi-part Data Science 
Professional Certificate series (PH125x) and intends to apply all the tools learned throughout 
the series. In this final project we were allowed to choose the prediction problem and dataset ourselves. As I'm a great fan of crime fiction and also find forensic science and analytics absolutely fascinating I decided to analyze the London Crime dataset which is publicly available on Kaggle (source: https://www.kaggle.com/jboysen/london-crime, accessed on 04/05/2020). To make the prediction problem a bit more challenging I've added another dataset, London Boroughs, with socio-demographic data for the boroughs of London (source: https://www.kaggle.com/marshald/london-boroughs, accessed on 04/10/2020). Unlike London Crime, this dataset is not an ML-friendly or cleaned dataset and needed some data wrangling before I could get started with the analysis and predictions.
&nbsp;

The goal of this project is to generate predictions for the number of crimes of the different boroughs. The socio-demographic information of these boroughs, like population density, average age or employment rate, will be used to predict the number of crimes.
&nbsp;

First of all, we will start out with the data preparation needed to create the cleaned and combined dataset. This will be followed by an inital data exploration to get an overview and first impression of the dataset. Next, we will dive into a detailed exploratory analysis of the four different groups of variables and figure out which of them are the most promising predictors that we should later include in our prediction model. During the development of the prediction, we will try different models and combinations of predictors in order to get to the best suited model. We will start with the simple Average as a base prediction, followed by Linear Regression. Then we will try two more advanced algorithms which are K-Nearest Neighbours and a Regression Tree using the ```rpart``` package.
Forecast accuracy will be evaluated based on the Residual Mean Square Error (RMSE). Finally, a conclusion will briefly summarize the key findings and limitations of the project.


\newpage

# Data Preparation

As we have two datasets, one already ML-friendly and clean and one first needing some cleaning, severeal data preparation steps need to be performed before we can actually start the analysis. 

&nbsp;

## Create the Combined Dataset

The London Crime dataset with it's original content contains seven variables (excluding the first column, which is just an index, see table below). Two of the variables are about the area the crime happened
(```lsoa_code``` and ```borough```), two describing the crime (```major_category``` and ```minor_category```), two about the ```month``` and ```year``` the reported crime happened and lastly the number of crimes (```value```).

```{r explore londoncrimes, include=TRUE, echo=FALSE}
head(londoncrime_temp) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```

This data is available for 2008 to 2016. I thought it would be very interesting to find out more about the single boroughs and the population that lives there in order to gain more insights into the crime occurences and predict them. Therefore I searched for socio-demographic data of the boroughs of London which I could add to the dataset. The London Boroughs dataset I found only has data from 2016, apart from the employment data, which is from 2015. Surely it would have been even better if the socio-demographic data would have been available for a longer time period to analyze several years, however, I know from experience that a perfect database is rarely available in real-life problems. Thus, I decided to go with this anyways and drop the years 2008 to 2015 from the London Crime dataset in favor of having a larger pool of variables by adding the London Boroughs dataset. This means we will focus on the year 2016 only.

The London Crime dataset is already clean, so we only have to do a little bit of data preparation. I've added a column combining year and month, and then aggregated the dataset without the first two columns, as the first column is just an index and the second column is the ```lsoa_code```, which we don't need. LSOA is the abbreviation for "Lower Super Output Area" and basically represents a more granular division of the Metropolitan Area of London than the boroughs. Due to the fact that we are going to predict crimes per borough, we don't need this variable and can downsize the dataset with this aggregation. The resulting dataset is shown in the table below.

&nbsp;

```{r data prep londoncrimes, include=TRUE, echo=TRUE}
# add a new column to londoncrime which combines year and month
londoncrime_temp$date <- with(londoncrime_temp, sprintf("%d-%02d", year, month))

# aggregate the dataset without the first two columns 
# (one is just an index and lsoa_code is not needed and just makes the dataset much bigger)
londoncrime_temp <- londoncrime_temp %>%
  group_by(borough, major_category, minor_category, year, month, date) %>%
  summarize(value = sum(value)) %>%
  select(borough, major_category, minor_category, value, year, month, date)

# change class into tibble
londoncrime_temp <- as_tibble(londoncrime_temp)

# check the resulting dataset
head(londoncrime_temp) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```

The London Boroughs dataset has 40 rows and 85 columns, which include a large variety of different variables, ranging from population size to age, employment data and even waste recycling rates and turnouts at local elections. The table shows an exerpt of some selected variables.

&nbsp;

```{r dim londonboroughs, include=TRUE, echo=TRUE}
# check dimensions of london boroughs dataset
dim(londonboroughs_temp)
```

&nbsp;

```{r explore londonboroughs, include=TRUE, echo=FALSE}
# exerpt of london boroughs dataset
head(londonboroughs_temp) %>%
  select(New.code, Area.name, Inner..Outer.London, GLA.Population.Estimate.2016, 
        GLA.Household.Estimate.2016) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

head(londonboroughs_temp) %>%
  select(Average.Age..2016, Employment.rate......2015., 
        Household.Waste.Recycling.Rate..2014.15, Turnout.at.2014.local.elections) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```

It is clear that this dataset needs a bit more preparation, as there are empty rows, NAs, whitespaces infront of numbers, unfavorable headings and some totals for England, United Kingdom, Inner and Outer London added to the borough column. However, once this is cleaned, we will have some very interesting socio-demographic information for every borough in the London Crime dataset. 

First of all, we are going to pick out the most interesting variables, as analyzing all 85 in detail would go beyond the scope of this project. We can also rename them, remove the first row, which is blank, and remove the last six rows containing additional data for total UK, England et cetera. Furthermore we replace the dots with the value "NA", remove the whitespace infront of the numbers and change the class to numeric. The resulting dataset is shown in the table below. 

&nbsp;

```{r data prep londonboroughs, include=TRUE, echo=TRUE}
# extract the relevant columns from the dataset and rename them
londonboroughs <- londonboroughs_temp %>%
  select(Area.name, GLA.Population.Estimate.2016, 
         GLA.Household.Estimate.2016, Inland.Area..Hectares., 
         Population.density..per.hectare..2016, Average.Age..2016,
         Proportion.of.population.aged.0.15..2016, 
         Proportion.of.population.of.working.age..2016,
         Proportion.of.population.aged.65.and.over..2016, 
         Employment.rate......2015., Male.employment.rate..2015., 
         Female.employment.rate..2015., 
         Unemployment.rate..2015.) %>%
  setnames(c("Area.name", "GLA.Population.Estimate.2016", 
              "GLA.Household.Estimate.2016", "Inland.Area..Hectares.", 
              "Population.density..per.hectare..2016", "Average.Age..2016",
              "Proportion.of.population.aged.0.15..2016", 
              "Proportion.of.population.of.working.age..2016",
              "Proportion.of.population.aged.65.and.over..2016", 
              "Employment.rate......2015.", "Male.employment.rate..2015.", 
              "Female.employment.rate..2015.", 
              "Unemployment.rate..2015."),
            c("borough", "population", "household", "hectares", "population_density", 
              "avg_age", "population_under_16", "population_working_age", "population_over_64", 
              "employment_rate_2015", "employment_rate_male_2015", "employment_rate_female_2015", 
              "unemployment_rate_2015"))

# remove the first row (this row is blank)
londonboroughs <- londonboroughs[-1,]

# remove the last 6 rows (these rows contain additional data for total UK, England etc., which we
# don't need)
londonboroughs <- londonboroughs[-c(34:39),]

# replace the "." with "NA"
londonboroughs[londonboroughs == "."] <- NA

# remove whitespace infront of the numbers in the columns population and household
londonboroughs <- londonboroughs %>% 
  mutate_at(2:3, str_trim)

# set format to numeric for the columns which are saved as characters at the moment (parse_number
# removes the commas and converts to numeric)
londonboroughs <- londonboroughs %>% 
  mutate_at(2:5, parse_number)

londonboroughs <- londonboroughs %>% 
  mutate_at(11:13, parse_number)

# check the resulting dataset
str(londonboroughs)

```

&nbsp;

```{r cleaned londonboroughs, include=TRUE, echo=FALSE}
londonboroughs %>%
  head() %>%
  select(borough, population, household, hectares, population_density, avg_age, population_under_16,
         population_working_age) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

londonboroughs %>%
  head() %>%
  select(population_over_64, employment_rate_2015, employment_rate_male_2015, 
         employment_rate_female_2015, unemployment_rate_2015) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```

Now that we have both datasets cleaned and in the same format, we can just combine them. 

&nbsp;

```{r combined dataset, include=TRUE, echo=TRUE}
# add the information of the londonboroughs dataset to the londoncrime dataset
londoncrime <- left_join(londoncrime_temp, londonboroughs, by = "borough")

# check the resulting dataset
str(londoncrime)

# remove the temporary datasets
rm(londonboroughs_temp, londoncrime_temp)

```

&nbsp;


## Missing Value for City of London

Unfortunately, there is one missing value in our dataset. There is no ```employment_rate_male_2015``` given for the borough "City of London", but we will later need this variable for our prediction model. Due to the fact that we only have a total of 33 boroughs, we don't really want to just remove this borough from the dataset. So how should we deal with the missing value?

```{r missing value tab, include=TRUE, echo=FALSE}
# show employment rate and employment rate 2015 for all boroughs
londoncrime %>%
  group_by(borough) %>%
  filter(borough %in% c("Barking and Dagenham", "Barnet", "Bexley", "Brent", "Bromley", 
         "Camden", "City of London", "Croydon", "Ealing")) %>%
  summarize(employment_rate_2015 = unique(employment_rate_2015), 
            employment_rate_male_2015 = unique(employment_rate_male_2015), 
            delta = employment_rate_male_2015 - employment_rate_2015,
            delta_prcnt = round((delta / employment_rate_2015 * 100), 1)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```


As we said, we only have a small number of boroughs, so just excluding this borough from the analysis seems like an unfavourable solution. Unfortunately it is completely unclear why this value is missing from the dataset. Is there a reason the employment rate can't be reported for the City of London? Is it not missing at random, but depends on the hypothetical value (e.g. similar to a logic like "missing value for salary -> people with high salaries generally do not want to reveal their incomes in surveys")? Does the City of London have similar characteristics to certain other boroughs which we could use for forming an assumption? Would we introduce bias by excluding this borough or forming an unfortunate assumption for the employment rate? I've researched how to deal with this problem on the internet and a very nice overview of different approaches can be found on towardsdatascience.com (https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4, accessed on 04/19/2020).

For the problem at hand I've decided on the following:

* We will form an assumption for the employment rate male for borough City of London rather than excluding it.
* The table above shows that for all other boroughs the employment rate male is higher than the employment rate overall (male & female). We will use this insight to derive an assumption for the employment rate male based on the overall employment rate for City of London.
* The prediction we will use is ```employment_rate_2015``` for City of London + average ```delta_prcnt``` that the other boroughs show (```delta_prcnt``` = difference between male and overall employment rate in percent)


```{r missing value prediction, include=TRUE, echo=FALSE}
# compute difference between overall employment rate and employment rate male for all boroughs
tab <- londoncrime %>%
  group_by(borough) %>%
  summarize(employment_rate_2015 = unique(employment_rate_2015), 
            employment_rate_male_2015 = unique(employment_rate_male_2015)) %>%
  mutate(delta = employment_rate_male_2015 - employment_rate_2015,
            delta_prop = (delta / employment_rate_2015))

# compute estimate for City of London
estimate_CoL <- tab %>%
  filter(borough != "City of London") %>%
  summarize(estimate = 1 + mean(delta_prop)) %>%
  .$estimate

# add the estimated employment rate male to the dataset
londoncrime <- londoncrime %>%
  mutate(employment_rate_male_2015 = case_when(
    borough == "City of London" ~ employment_rate_2015 * estimate_CoL,
    TRUE ~ employment_rate_male_2015))

# check the resulting dataset
londoncrime %>%
  group_by(borough) %>%
  filter(borough %in% c("Barking and Dagenham", "Barnet", "Bexley", "Brent", "Bromley", 
         "Camden", "City of London", "Croydon", "Ealing")) %>%
  summarize(employment_rate_2015 = unique(employment_rate_2015), 
            employment_rate_male_2015 = round(unique(employment_rate_male_2015), 1)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

# remove the temporary datasets and variables
rm(tab)

```

The resulting prediction for the ```employment_rate_male_2015``` for City of London is 70.3. 

&nbsp;


## Split the Dataset into Train, Test and Validation Sets

Similar to the validation in the MovieLens Project, we will first seperate a validation dataset and then split the remaining dataset into a train and test set. This means we can perform full cross-validation. The validation dataset will only be used at the very end of this project to evaluate the performance of the final algorithm. During model building we will use the train dataset to train each algorithm and use the test dataset to tune parameters and evaluate which algorithm seems most promising.

We have two conflicting goals here: on the one hand, we would like to have the largest possible database to train our model with, because this should improve our model performance. On the other hand, our test or validation datasets should not be too small, otherwise we will get very imprecise performance results, because we are just evaluating against a handful, maybe very uncommon data records. Common approaches for splits are 80:20, 90:10 or even 50:50. Considering that we want to split into three datasets this would translate into 60/20/20, 80/10/10 and 33/33/33 as a proportion for the train/test/validation set. In the problem at hand we have a total of 33 boroughs, so 10% of the boroughs would be just 3 boroughs (rounded, as we have to look at each borough as a whole and can't split it). This seems to be a very small number for evaluation. On the other hand, 33% of the boroughs would be 11 boroughs, which would be a very small number for training. Thus, a split of 60/20/20 seems to be the most favourable option in this case.
This means we will split our dataset into 6 randomly selected boroughs for validation and another 6 randomly selected for testing, which leaves 21 boroughs for trainig.
Now we are all set for starting with the exploratory data analysis (EDA) on the training dataset in the next chapter.

&nbsp;

```{r split train test validation, include=TRUE, echo=TRUE}
# create auxiliary table for boroughs
boroughs <- londoncrime %>%
  group_by(borough) %>%
  summarize(crimes = sum(value))

# randomly select 6 of the 33 boroughs
set.seed(9)
index_validation <- boroughs[sample(nrow(boroughs), 6), ] %>%
  .$borough

# seperate the data of the randonly selected boroughs to get the validation dataset
validation <- londoncrime %>%
  filter(borough %in% index_validation)

# remove the boroughs in the validation set from the list of boroughs
boroughs <- boroughs %>%
  filter(!borough %in% index_validation)

# then do the same to split the remaining dataset into a train and test set we can use to build
# our model
index_test <- boroughs[sample(nrow(boroughs), 6), ] %>%
  .$borough

test <- londoncrime %>%
  filter(borough %in% index_test)

# create the train set with the rest of the data
train <- londoncrime %>%
  filter(!borough %in% c(index_validation, index_test))

# check that separation went fine
nrow(test) + nrow(train) + nrow(validation) == nrow(londoncrime)


# double check that split into validation, train and test set is ok as far as % of the original
# dataset is concerned -> both make up about 20% of the original london crime dataset
nrow(validation) / (nrow(londoncrime)) * 100
nrow(test) / (nrow(londoncrime)) * 100
nrow(test) / (nrow(train) + nrow(test)) * 100

```



\newpage

# Exploratory Data Analysis 

To fully understand the dataset we will now explore all variables and also try to figure out correlations between them. The insights gained in this chapter will help us select the right prediction methods for our problem as well as the most important predictors to include.
The goal is to predict number of crimes per month and borough, so we need to look for factors that influence the number of crimes. 
Analytics has been used in criminology for a long time. The problem at hand surely is a rather small prediction problem, however, it could still serve a practical purpose. Like any other organisation, the police also has to do mid- and long-term resource planning, and predicting the development of the number of crimes over the next years could help to estimate how many police resources will be needed and where to best put these limited resources. Surely, the police has experience with crime occurences and the severe crime hot-spots are already known, but a large metropolitan area like London is constantly evolving and you would want to discover new trends and changing characteristics as early as possible to be able to react appropriately. 

&nbsp;


## Get a First Impression of the Dataset

The train dataset contains a bit more than 8.000 data records and 19 different variables. We can see the name of the borough, the major and minor category of the crime, the number of crimes (```value```) as well as the year and month the crime was reported and the combined variable of year and month which we've added in the data preparation. The next four variables are GLA 2016-based population estimates and show the population size living in each borough, the number of households, the hectares of the borough and the population density (per hectare). Furthermore, we have another four variables about the age of the borough population, which include average age, proportion of the population with an age under 16 (age 0-15), population proportion in working age (age 16-64) and population proportion over 64 (age 65 and over). Finally, there are another four variables about the labour market, the overall employment rate, the male employment rate, the female employment rate and the unemployment rate. These four variables are from 2015, whereas all other variables are from 2016. 

```{r first impression, include=TRUE, echo=FALSE}
head(train) %>%
  select(borough, major_category, minor_category, value, year, month, date, population, 
         household) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

head(train) %>%
  select(hectares, population_density, avg_age, population_under_16, population_working_age,
         population_over_64) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

head(train) %>%
  select(employment_rate_2015, employment_rate_male_2015,
         employment_rate_female_2015, unemployment_rate_2015) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```

The table below shows the number of distinct major and minor categories as well as boroughs. Underneath are tables with all unique values for these three variables.


```{r n_distinct values, include=TRUE, echo=FALSE}
# distinct major and minor categories and boroughs
train %>% 
  summarize("Number of Major Categories" = n_distinct(major_category),
            "Number of Minor Categories" = n_distinct(minor_category),
            "Number of Boroughs" = n_distinct(borough)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```


```{r unique values, include=TRUE, echo=FALSE}
# unique major and minor categories and unique boroughs
train %>%
  group_by(major_category, minor_category) %>%
  summarize(crimes = sum(value)) %>%
  select("Major Category" = major_category, "Minor Category" = minor_category) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

train %>%
  group_by(borough) %>%
  summarize(crimes = sum(value)) %>%
  select("Borough" = borough) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```


```{r avg crimes, include=FALSE, echo=FALSE}
# average crimes per month
avg_crimes <- train %>% 
  summarize(avg_crimes = sum(value) / n_distinct(date)) %>% 
  .$avg_crimes

```

Over all boroughs, there are `r round(avg_crimes)` crimes reported per month on average. The chart shown below illustrates the number of crimes per month compared to this average. The number of crimes per month vary a bit with higher Jan, Mar, May, Jul, Oct and Dec versus lower Feb, Apr, Jun, Aug, Sep and Nov. Overall there seems to be an increasing trend as well, as Jan to Apr are below average, but all months after May are above average. 


```{r crimes per month, include=TRUE, echo=FALSE, fig.width=6, fig.height=3}
# number of crimes per month
train %>% 
  group_by(month) %>%
  summarize(crimes = sum(value)) %>%
  ggplot(aes(month, crimes)) +
  geom_line(color = "steelblue4", size = 1) +
  geom_abline(intercept = avg_crimes, color = "grey", lty = 2) + 
  ylim(0, 50000) +
  scale_x_continuous(breaks = c(1:12)) +
  theme_classic() +
  labs(title = "Number of Crimes per Month and Period Average",
       x = "Month", y = "Number of Crimes") 

```

Could the monthly up and down pattern have to do with different number of days per month?

Looking at the charts with average crimes per day, one with the y-axis starting at 0, one displaying more detail with the y-axis starting at 1.000, we can see that some of the variation seems to have levelled out if one considers the different number of days. Now the pattern more looks like it could be driven by school holidays (e.g. Easter in Mar/Apr, summer holidays in Aug) and seasonality, maybe due to weather conditions. However, this is not the focus of the project and we don't have the necessary data to further investigate this, so we'll leave it at that. 


```{r avg crimes per day, include=TRUE, echo=FALSE, fig.width=6, fig.height=3}
# calculate average crimes per day for each month
crimes_per_day <- train %>%
  group_by(month) %>%
  summarize(crimes = sum(value)) %>%
  select(month, crimes) %>%
  mutate(days = c(31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31), avg_crimes_day = crimes / days)

# plot average crimes per day for each month
crimes_per_day %>%
  ggplot(aes(month, avg_crimes_day)) +
  geom_line(color = "steelblue4", size = 1) +
  ylim(0, 2000) +
  scale_x_continuous(breaks = c(1:12)) +
  theme_classic() +
  labs(title = "Average Crimes per Day for each Month",
       x = "Month", y = "Number of Crimes") 

# same chart but with smaller scale to see more detail
crimes_per_day %>%
  ggplot(aes(month, avg_crimes_day)) +
  geom_line(color = "steelblue4", size = 1) +
  ylim(1000, 1500) +
  scale_x_continuous(breaks = c(1:12)) +
  theme_classic() +
  labs(title = "Average Crimes per Day for each Month (detailed view)",
       x = "Month", y = "Number of Crimes") 

```

Westminster is the borough with the highest number of crimes, followed by Southwark and Newham. Kingston upon Thames has the lowest number of crimes in our train dataset. 


```{r crimes per borough, include=TRUE, echo=FALSE, fig.width=6, fig.height=4}
# number of crimes per borough 
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value)) %>%
  ggplot(aes(reorder(borough, -crimes), crimes)) +
  geom_bar(stat = "identity", fill = "steelblue4") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Number of Crimes per Borough",
       x = "", y = "Number of Crimes")

```

The number of crimes in each borough seems to be relatively stable over those 12 months. This suggests that linear regression should be a good prediction method to start with. Only single spikes, like in Westminster in Jul, Aug and Dec are striking. However, boroughs seem to be quite different, some range around 1.000 crimes per month, some show much higher numbers, e.g. Westminster which ranges around 4.000 crimes per month. 


```{r crimes per month and borough, include=TRUE, echo=FALSE, fig.width=11, fig.height=8}
# number of crimes per month and borough (faceted line chart, descending order)
train %>% 
  group_by(month, borough) %>%
  summarize(crimes = sum(value)) %>%
  mutate(borough = reorder(borough, -crimes)) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(c(0, 5000)) +
  scale_x_continuous(breaks = c(1:12)) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Number of Crimes per Month and Borough",
       x = "Month", y = "Number of Crimes")

```

&nbsp;


## Explore the Dataset in Detail

Now that we've gotten a first impression of the dataset, we will throughly analyze the different sets of variables. The goal is to 1) get a good understanding of the dataset and 2) find insights like a correlation between a variable and the number of crimes, so we know which variables we should later include in our prediction model.

The variables can be grouped in the following manner:  

* Type of Crime: Major and Minor Category

* Population Size: Population, Household, Hectares and Population Density

* Population Age: Average Age, Population under 16, Population in Working Age and Population over 64

* Employment: Employment Rate, Employment Rate Male, Employment Rate Female and Unemployment Rate  

&nbsp;


### Type of Crime

By far the highest number of crimes belong to the categories Theft and Handling as well as Violence Against the Person. There are no crimes documented with major category Fraud or Forgery and Sexual Offences.

```{r crimes by major category, include=TRUE, echo=FALSE, fig.width=4.5, fig.height=3.5}
# number of crimes by major category
train %>% 
  group_by(major_category) %>%
  summarize(crimes = sum(value)) %>%
  ggplot(aes(reorder(major_category, -crimes), crimes)) +
  geom_bar(stat = "identity", fill = "steelblue4") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Number of Crimes by Major Category",
       x = "", y = "Number of Crimes")

```

Other Theft is the minor category with the highest number of crimes, followed by Harassment and Common Assault. The latter two belong to the major category Violence Against the Person.

```{r crimes by minor category, include=TRUE, echo=FALSE, fig.width=7, fig.height=5}
# number of crimes by minor category
train %>% 
  group_by(minor_category) %>%
  summarize(crimes = sum(value)) %>%
  ggplot(aes(reorder(minor_category, -crimes), crimes)) +
  geom_bar(stat = "identity", fill = "steelblue4") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Number of Crimes by Minor Category",
       x = "", y = "Number of Crimes")

```

Combining the two categories, we can see that the seven top minor categories all belong to the major categories Theft and Handling and Violence Against the Person. Only in eighth place follows the minor category Burglary in a Dwelling which belongs to major category Burlary. Next is Possession of Drugs which belongs to major category Drugs.

```{r crimes by major and minor category, include=TRUE, echo=FALSE, fig.width=11, fig.height=6}
# number of crimes by major and minor category (without Fraud or Forgery and Sexual Offences as 
# these are zero and would just unnecessarily clutter the chart)
train %>% 
  group_by(major_category, minor_category) %>%
  filter(!major_category %in% c("Fraud or Forgery", "Sexual Offences")) %>%
  summarize(crimes = sum(value)) %>%
  ggplot(aes(reorder(minor_category, -crimes), crimes, color = major_category, 
             fill = major_category)) +
  geom_bar(stat = "identity") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Number of Crimes by Major and Minor Category",
       x = "", y = "Number of Crimes")

```

Especially Theft and Handling seems to be driving the overall trend of a rising number of crimes. Violence Against the Person also contributes a lot to the rising number of crimes during the middle of the year, but then decreases again. The other five categories are relatively stable over time, only Burglary and Criminal Damage have switched places during the course of the year.

```{r crimes per major cat and month, include=TRUE, echo=FALSE, fig.width=9, fig.height=3.5}
# number of crimes per major category and month (without Fraud or Forgery and Sexual Offences as 
# these are zero and would just unnecessarily clutter the chart)
train %>% 
  group_by(month, major_category) %>%
  filter(!major_category %in% c("Fraud or Forgery", "Sexual Offences")) %>%
  summarize(crimes = sum(value)) %>%
  ggplot(aes(month, crimes, color = major_category)) +
  geom_line(size = 1) +
  scale_color_discrete(name = "Major Category") +
  scale_x_continuous(breaks = c(1:12)) +
  theme_classic() +
  labs(title = "Number of Crimes per Month",
       x = "Month", y = "Number of Crimes") 

```


&nbsp;


### Population Size and Crimes 

In this section we will investigate whether there is any correlation between the population variables and the number of crimes per borough. As the boroughs have a quite different size taking the absolute numbers, we will first compute the number of crimes per 100.000 residents to check whether there is a striking difference between the boroughs. However, the chart shows that the overall picture is still unchanged, by far the highest number of crimes is reported for Westminster. Then there is a slowly decreasing number over the other boroughs.

```{r crimes per 100.000, include=TRUE, echo=FALSE, fig.width=5, fig.height=3.5}
# subset with population per 100.000 residents
crime_and_population <- train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population = unique(population)) %>%
  mutate(crimes_per_100.000 = (crimes / population) * 100000) %>%
  arrange(desc(crimes_per_100.000))

crime_and_population %>% 
  ggplot(aes(reorder(borough, -crimes_per_100.000), crimes_per_100.000)) +
  geom_bar(stat = "identity", fill = "steelblue4") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Number of Crimes per 100.000 Residents",
       x = "", y = "Number of Crimes") 

```

The scatterplot of crimes versus population size reveals that highly populated boroughs have a higher number of documented crimes. The same applies to crimes versus number of households in each borough. This correlation seems even clearer between crimes and population density. Logically, this also makes sense, as a densly populated area should offer both more potential victims and offenders, more opportunities to commit a crime and a highler potential for conflicts due to the crowdedness.

```{r crimes and population, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and population size for each borough
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population = unique(population)) %>%
  ggplot(aes(population, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  xlim(c(0, 400000)) +
  ylim(c(0, 50000)) +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Population Size",
       x = "Population", y = "Number of Crimes") 

```


```{r crimes and households, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and households for each borough
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), household = unique(household)) %>%
  ggplot(aes(household, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  xlim(c(0, 150000)) +
  ylim(c(0, 50000)) +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Households",
       x = "Households", y = "Number of Crimes") 

```


```{r crimes and population density, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population_density = unique(population_density)) %>%
  ggplot(aes(population_density, crimes, color = borough)) +
  geom_point(size = 4) +
  xlim(c(0, 180)) +
  ylim(c(0, 50000)) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Population Density",
       x = "Population Density", y = "Number of Crimes") 

```

In contrast, hectares seems like a less promising indicator for high number of crimes compared to population, households or population density. Hillingdon, for example, has about the same number of crimes as Islington but they have completely different hectares.

```{r crimes and hectares, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and hectares for each borough
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), hectares = unique(hectares)) %>%
  ggplot(aes(hectares, crimes, color = borough)) +
  geom_point(size = 4) +
  xlim(c(0, 20000)) +
  ylim(c(0, 50000)) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Hectares",
       x = "Hectares", y = "Number of Crimes") 

```


&nbsp;

**Correlation Coefficient**

We now have three variables (population, household, population density) that we could use as predictors for the number of crimes, but logically they should all be correlated with each other. Thus, we don't want to include all three of them in a prediction model, as all kind of measure the same issue. We just want to include the strongest predictor of them, to keep our model nice and concise, instead of bloating it with all variables we can get our hands on. To find out which of the three has the strongest relationship with number of crimes, we are going to compute the correlation coefficient.
The correlation coefficient *r* measures the strength and direction of a linear relationship between two variables on a scatterplot. The value of *r* is always between +1 and â€“1, where 0 means no relationship, +1 is a perfect positive relationship and -1 translates to a perfect negative relationship (source: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient, accessed on 05/01/2020). We've used the R function ```cor()``` with the default method here, which is the Pearson Correlation Coefficient, according to the R Documentation (source: https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/cor, accessed on 05/01/2020).


```{r cor between pop vars, include=TRUE, echo=FALSE}
# calculate correlation coefficient for population variables
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population = unique(population), 
            household = unique(household), population_density = unique(population_density), 
            hectares = unique(hectares)) %>%
  summarize(cor(population, household), cor(population, population_density),
            cor(population, hectares)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population = unique(population), 
            household = unique(household), population_density = unique(population_density), 
            hectares = unique(hectares)) %>%
  summarize(cor(household, population_density), cor(household, hectares), 
            cor(population_density, hectares)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```

Between the population variables, there are the following correlations, based on the correlation coefficient calculated with the train dataset:

* high positive correlation between population and households

* very weak negative correlation between population and population density

* medium positive correlation between population and hectares

* weak positive correlation between households and population density

* medium positive correlation between households and hectares

* strong negative correlation between population density and hectares


Next, we compute the correlation coefficient for the population variables versus number of crimes. We can read from the table below that the strongest correlation is crimes versus households, followed by crimes and population density. Same as in the scatterplot, crimes and hectares seem to have only a weak negative correlation based on the correlation coefficient. Population and households are very strongly correlated with each other, so we will just include one of them in the prediction model, which is households as the correlation to crimes is the strongest.

```{r cor crimes and pop vars, include=TRUE, echo=FALSE}
# calculate correlation coefficient for crimes vs. population variables
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population = unique(population), 
            household = unique(household), population_density = unique(population_density), 
            hectares = unique(hectares)) %>%
  summarize(cor(crimes, population), cor(crimes, household), cor(crimes, population_density),
            cor(crimes, hectares)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```

&nbsp;


### Population Age and Crimes

Similar to the variables about population size, we are now going to analyze the four variables revolving about population age. Why could population age play a role for the number of crimes? Again this is a matter of potential offenders and victims as well as opportunities for crime. Young children and elderly people are very unlikely to commit crimes. However, especially elderly people are often quite vulnerable for crimes and e.g. fall victim to theft. 

The charts below illustrate that there could be a weak negative correlation between average age and crimes. The same applies to crimes and population proportion under 16 as well as population proportion over 64. So generally speaking, a high proportion of children and teenagers or elderly people suggest a borough with a lower number of crimes. On the contrary, population proportion in working age seems to be positively correlated with crimes. In all cases, Westminster seems to be somewhat of an outlier again. Overall, the population age seems to have only little effect on the total number of crimes, as all correlations appear to be rather weak.

```{r crimes and avg age, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and average age of the population
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), avg_age = unique(avg_age)) %>%
  ggplot(aes(avg_age, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Average Age of the Population",
       x = "Average Age", y = "Number of Crimes") 

```


```{r crimes and pop under 16, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and population proportion under 16
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population_under_16 = unique(population_under_16)) %>%
  ggplot(aes(population_under_16, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  theme(legend.position = "none") + 
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  labs(title = "Number of Crimes and Population under 16",
       x = "Population Proportion under 16", y = "Number of Crimes") 

```


```{r crimes and working age, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and population proportion in working age
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population_working_age = unique(population_working_age)) %>%
  ggplot(aes(population_working_age, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  theme(legend.position = "none") + 
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  labs(title = "Number of Crimes and Population in Working Age",
       x = "Population Proportion in Working Age", y = "Number of Crimes") 

```


```{r crimes and pop over 64, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and population proportion over 64
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), population_over_64 = unique(population_over_64)) %>%
  ggplot(aes(population_over_64, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Population over 64",
       x = "Population Proportion over 64", y = "Number of Crimes") 

```

The correlation coefficients confirm our findings from the scatterplots. The relationship between crimes and average age seems to be the strongest.

```{r cor crimes and age vars, include=TRUE, echo=FALSE}
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), avg_age = unique(avg_age), 
            population_under_16 = unique(population_under_16), 
            population_working_age = unique(population_working_age), 
            population_over_64 = unique(population_over_64)) %>%
  summarize(cor(crimes, avg_age), cor(crimes, population_under_16), 
            cor(crimes, population_working_age), cor(crimes, population_over_64)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```

&nbsp;



### Employment and Crimes

The reason to include a variable about employment or unemployment in a prediction model for crimes is pretty straightforward. Naturally, crimes are higher in a period of high unemployment as people are less likely to be able to fulfill their needs and earn money through a legal occupation. Furthermore unemployment drives insecurity, instability and conflict potential, which all foster crimes.

The bar chart of employment rates per borough reveals that the employment rates seem to be relatively high in all boroughs. Interestingly, Westminster which was the borough with the highest number of crimes, has the lowest employment rate. Suburban boroughs like Richmond upon Thames and Merton have the highest employment rates and are among the boroughs with the least crimes.

```{r employment rate per borough, include=TRUE, echo=FALSE, fig.width=6, fig.height=4}
# employment rate per borough
train %>% 
  group_by(borough) %>%
  summarize(employment_rate_2015 = unique(employment_rate_2015)) %>%
  ggplot(aes(reorder(borough, -employment_rate_2015), employment_rate_2015)) +
  geom_bar(stat = "identity", fill = "steelblue4") +
  ylim(c(0, 100)) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 58, vjust = 1, hjust = 1)) +
  labs(title = "Employment Rate per Borough",
       x = "", y = "Employment Rate")

```

The scatterplots for crimes versus the four employment variables show that there is somewhat of a negative correlation between crimes and employment. The relationship between male employment rate and crimes appears to be the strongest, whereas the relationship between female employment rate and crimes appears to be the weakest.

```{r crimes and employment rate, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and employment rate
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), employment_rate_2015 = unique(employment_rate_2015)) %>%
  ggplot(aes(employment_rate_2015, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Employment Rate",
       x = "Employment Rate", y = "Number of Crimes") 

```


```{r crimes and male employment rate, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and male employment rate
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), employment_rate_male_2015 = unique(employment_rate_male_2015)) %>%
  ggplot(aes(employment_rate_male_2015, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Male Employment Rate",
       x = "Male Employment Rate", y = "Number of Crimes") 

```


```{r crimes and female employment rate, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and female employment rate
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), employment_rate_female_2015 = unique(employment_rate_female_2015)) %>%
  ggplot(aes(employment_rate_female_2015, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Female Employment Rate",
       x = "Female Employment Rate", y = "Number of Crimes") 

```


```{r crimes and umemployment rate, include=TRUE, echo=FALSE, fig.width=5, fig.height=4, fig.align='left'}
# number of crimes and unemployment rate
train %>% 
  group_by(borough) %>%
  summarize(crimes = sum(value), unemployment_rate_2015 = unique(unemployment_rate_2015)) %>%
  ggplot(aes(unemployment_rate_2015, crimes, color = borough)) +
  geom_point(size = 4) +
  theme_classic() +
  geom_text_repel(aes(label = borough), size = 2, hjust = -0.2) +
  xlim(c(0, 100)) +
  ylim(c(0, 50000)) +
  theme(legend.position = "none") + 
  labs(title = "Number of Crimes and Unemployment Rate",
       x = "Unemployment Rate", y = "Number of Crimes")

```


Due to the fact that the employment rates male and female are missing from the dataset for the borough City of London and we have only formed an assumption for the employment rate male, the correlation coefficients shown below are excluding the borough City of London. 
Still, the findings from the scatterplots are again confirmed by the correlation coefficient which shows the strongest correlation between crimes and employment rate male.

```{r cor crimes and employment vars, include=TRUE, echo=FALSE}
train %>% 
  group_by(borough) %>%
  filter(borough != "City of London") %>%
  summarize(crimes = sum(value), employment_rate_2015 = unique(employment_rate_2015), 
            employment_rate_male_2015 = unique(employment_rate_male_2015), 
            employment_rate_female_2015 = unique(employment_rate_female_2015), 
            unemployment_rate_2015 = unique(unemployment_rate_2015)) %>%
  summarize(cor(crimes, employment_rate_2015), cor(crimes, employment_rate_male_2015)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

train %>% 
  group_by(borough) %>%
  filter(borough != "City of London") %>%
  summarize(crimes = sum(value), employment_rate_2015 = unique(employment_rate_2015), 
            employment_rate_male_2015 = unique(employment_rate_male_2015), 
            employment_rate_female_2015 = unique(employment_rate_female_2015), 
            unemployment_rate_2015 = unique(unemployment_rate_2015)) %>%
  summarize(cor(crimes, employment_rate_female_2015), cor(crimes, unemployment_rate_2015)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

# remove the temporary datasets that are not needed anymore
rm(crime_and_population, crimes_per_day)
```

&nbsp;
&nbsp;


**Results of the Exploratory Data Analysis** 

The number of crimes varies depending on months and is also influenced by the population living in the respective area. The most promising predictors to include in our prediction model seem to be months, households, population density as well as average age and male employment rate.




\newpage

# Prediction Model 

This chapter is devoted to the development of the prediction model. During the analysis we have found out that regression should be a suitable method to use and we have identified the most important predictors in our dataset. Before we can actually start with different models, we have to define the metric we want to evaluate our models with. 

```{r set seed, include=FALSE, echo=FALSE}
# set the seed for some of the predictions in this section
set.seed(1991)
```

&nbsp;


## Metric to Evaluate the Model: RMSE

Generally, there are various different metrics one can use to evaluate model performance. Very popular metrics are for example

* R-Squared (RÂ²)

* Adjusted R-Squared (Adj RÂ²)

* Mean Square Errors (MSE)

* Root Mean Squared Errors (RMSE).

There is no metric which is generally the best for any prediction problem. It highly depends on the data you are using as well as the prediction problem you want to solve. In the Machine Learing course (PH125.8x), for example, we were faced with a categorical outcome and intially used overall accuracy to evaluate our model, which is one of the simplest evaluation methods. Later we have moved on to studying sensitivity and specificity. "Sensitivity, also known as the true positive rate or recall, is the proportion of actual positive outcomes correctly identified as such. Specificity, also known as the true negative rate, is the proportion of actual negative outcomes that are correctly identified as such" (source: PH125.8x Machine Learning).

In our case, we have a continuous outcome, and RMSE is a suitable evaluation metric, as it tells us how close our predicted regression line is to the actual data points. Furthermore, RMSE is relatively easy to interpret, because it comes in the same unit as the predicted variable (source: https://towardsdatascience.com/predictive-modellers-guide-to-choosing-the-best-fit-regression-model-707120e502b4, accessed on 26/04/2020). So for the problem at hand an RMSE of 500 would mean that our prediction misses by 500 crimes per month.

Assuming that $\hat{y}_{i}$ are our predicted values, ${y}_{i}$ are the observed values and $n$ is the number of observations, we can write the formula for the RMSE as follows (source: https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e, accessed on 05/16/2020):

$$ RMSE = \sqrt{ \displaystyle \sum_{i=1}^n \frac{(\hat{y}_{i}-y_{i}) ^{2}} {n}}$$ 

```{r RMSE definition, include=TRUE, echo=FALSE}
# define the loss function (RMSE)
RMSE <- function(reported_crimes, predicted_crimes){
  sqrt(mean((reported_crimes - predicted_crimes)^2))
}

```

&nbsp;



## Base Prediction: Average

Our base prediction will be the monthly average. This means we would simply assume that the number of crimes only varies based on month, but other than that is the same for each borough, and all other variation is just random variation. The monthly average is given in the following table:

```{r avg prediction, include=FALSE, echo=FALSE}
# auxiliary table with boroughs and months to predict
match_table <- test %>%
  group_by(month, borough) %>%
  summarize(crimes = sum(value)) %>%
  select(month, borough)

match_table

# average crimes per month as prediction
avg_crimes <- train %>%
  group_by(month) %>%
  summarize(avg_crimes = sum(value) / n_distinct(borough))

avg_crimes

# join the match table and the average crimes per borough to get predicted values into a table
mu_temp <- left_join(match_table, avg_crimes, by = "month")
mu_temp

# leave only the avg crimes in table to evaluate against
mu <- mu_temp %>%
  .$avg_crimes
mu

# calculate reported crimes per borough and month in test set
reported_crimes_temp <- test %>%
  group_by(month, borough) %>%
  summarise(crimes = sum(value))

reported_crimes_temp

reported_crimes <- reported_crimes_temp %>%
  .$crimes

reported_crimes

# evaluate the prediction with the test set
rmse_naive <- RMSE(reported_crimes, mu)
rmse_naive

```


```{r show avg prediction, include=TRUE, echo=FALSE}
round(avg_crimes) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```

Using this prediction, we get an RMSE of `r round(rmse_naive)` on the test set. This means we are missing by over 700 crimes per month. Considering that Westminster was the borough with the higest number of crimes ranging around 4.000 per month and many boroughs had around 1.000 crimes per month, the RMSE seems quite high. We should certainly be able to beat this benchmark with more sophistcated prediction methods.
Just for fun I've also added a table with the output of the R function ```accuracy()```, in order to check out other evaluation metrics as well. The table shows the RMSE, but also ME (Mean Error), MAE (Mean Absolute Error), MPE (Mean Percentage Error) and MAPE (Mean Absolute Percentage Error) (source: https://www.rdocumentation.org/packages/forecast/versions/8.12/topics/accuracy, accessed on 05/16/2020).

```{r rmse results 1, include=TRUE, echo=FALSE}
# store the prediction results in a table
rmse_results <- tibble(Method = "Average Crimes per Borough", RMSE = round(rmse_naive))
rmse_results %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

# checking additional measures of forecast accuracy just for fun
round(accuracy(mu, reported_crimes), 0) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```

&nbsp;



## Linear Regression

The second prediction method we will try is Linear Regression. During the EDA we have found five variables that we could potentially include in our prediction model. As we don't really know yet how much each of them improves our prediction results, we will first start with the simplest version only including month and then subsequently add the other four variables while checking the RMSE for each version of the LM model. The code below shows the implementation in R. The dataset ```train_red``` is a reduced version of the train dataset, which only includes the variables needed for the regression. The LM prediction with month only is almost the same as just the simple average, so the RMSE are also almost the same.

&nbsp;

```{r reduced train, include=FALSE, echo=FALSE}
# put together the reduced dataset only including the variables needed for linear regression
train_red <- train %>%
  group_by(month, borough) %>%
  summarize(crimes = sum(value), household = unique(household), 
            population_density = unique(population_density), 
            avg_age = unique(avg_age),
            employment_rate_male_2015 = unique(employment_rate_male_2015)) %>%
  select(month, borough, crimes, household, population_density, 
         avg_age, employment_rate_male_2015)

test_red <- test %>%
  group_by(month, borough) %>%
  summarize(crimes = sum(value), household = unique(household), 
            population_density = unique(population_density), 
            avg_age = unique(avg_age),
            employment_rate_male_2015 = unique(employment_rate_male_2015)) %>%
  select(month, borough, crimes, household, population_density, 
         avg_age, employment_rate_male_2015)

# reorder reported crimes so we are matching the correct month and borough for the evaluation of
# the linear regression models
reported_crimes_temp <- test %>%
  group_by(month, borough) %>%
  summarise(crimes = sum(value))

reported_crimes_temp

reported_crimes <- reported_crimes_temp %>%
  .$crimes

reported_crimes
```


```{r fit lm0, include=TRUE, echo=TRUE}
# fit regression line to predict crimes
fit_lm0 <- lm(crimes ~ month, data = train_red)

# check out the statistics of the fit
tidy(fit_lm0, conf.int = TRUE)

# predict crimes for the test data with the fitted regression
predicted_crimes_lm0 <- predict(fit_lm0, newdata = test_red)

# evaluate the prediction with the test set
rmse_lm0 <- RMSE(reported_crimes, predicted_crimes_lm0)
round(rmse_lm0)

```

&nbsp;

By adding one variable at a time to the Linear Regression, we get another four models. The resulting RMSE for each of them are shown below. The model with month, households and population density performs best.

```{r fit other lm predictions, include=TRUE, echo=FALSE}
# predict crimes for the other possible lm models
fit_lm1 <- lm(crimes ~ month + household, data = train_red)
fit_lm2 <- lm(crimes ~ month + household + population_density, data = train_red)
fit_lm3 <- lm(crimes ~ month + household + population_density + avg_age, data = train_red)
fit_lm4 <- lm(crimes ~ month + household + population_density + avg_age +
            employment_rate_male_2015, data = train_red)

predicted_crimes_lm1 <- predict(fit_lm1, newdata = test_red)
predicted_crimes_lm2 <- predict(fit_lm2, newdata = test_red)
predicted_crimes_lm3 <- predict(fit_lm3, newdata = test_red)
predicted_crimes_lm4 <- predict(fit_lm4, newdata = test_red)

rmse_lm1 <- RMSE(reported_crimes, predicted_crimes_lm1)
rmse_lm2 <- RMSE(reported_crimes, predicted_crimes_lm2)
rmse_lm3 <- RMSE(reported_crimes, predicted_crimes_lm3)
rmse_lm4 <- RMSE(reported_crimes, predicted_crimes_lm4)

# store the prediction results in a table
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = c("LM month", 
                                            "LM month+households", 
                                            "LM month+households+density", 
                                            "LM month+households+density+age",
                                            "LM month+households+density+age+employment"), 
                                 RMSE = c(round(rmse_lm0), round(rmse_lm1), round(rmse_lm2),
                                          round(rmse_lm3), round(rmse_lm4))))

rmse_results %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```


```{r lm chart prep, include=FALSE, echo=FALSE}
# get the month column out of the test_red dataset and add it to predicted crimes
# in order to add the predictions to the chart later on
month_col <- test_red %>%
  .$month 
borough_col <- test_red %>%
  .$borough

predicted_crimes_lm0 <- as_tibble(predicted_crimes_lm0)
predicted_crimes_lm0 <- predicted_crimes_lm0 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_lm1 <- as_tibble(predicted_crimes_lm1)
predicted_crimes_lm1 <- predicted_crimes_lm1 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_lm2 <- as_tibble(predicted_crimes_lm2)
predicted_crimes_lm2 <- predicted_crimes_lm2 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_lm3 <- as_tibble(predicted_crimes_lm3)
predicted_crimes_lm3 <- predicted_crimes_lm3 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_lm4 <- as_tibble(predicted_crimes_lm4)
predicted_crimes_lm4 <- predicted_crimes_lm4 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)
```

Besides studying the RMSE results it is always helpful to visualize the prediction versus the actual observations. With a visualization it is much easier to understand what the model is predicting well and what it is not predicting well. The following charts illustrate the predictions as grey line versus the actual observations for each borough in our test dataset. 

Prediction 0 is especially off for boroughs Harrow, Lambeth and Sutton, whereas prediction 1, 2 and 4 are predicting the number of crimes worst for Barnet and Bromley. Prediction 0 was the prediction just using month, and Barnet and Bromley are very close to the overall monthly average, that's why this prediction works well for these two boroughs. Harrow, Havering and Sutton are suburban boroughs with a relatively low number of crimes and the predictions for these three boroughs gain a lot by adding households, population density, average age and employment rate male to the model. Lambeth has the highest number of crimes in the test set as well as a high number of households and by far the highest population density, so the prediction gains most through these two variables. The same applies for Barnet and Bromley, which have a high number of households, but a rather low population density, thus the LM prediction 1 only with households is considerably overestimating the number of crimes, whereas the LM prediction 2 additionaly including population density is much closer to the actuals. Barnet and Bromley apparently are rather untypical considering average age and employment rate male, thus the two last predictions are performing worse than prediction 2. 


```{r table for test set, include=TRUE, echo=FALSE}
# table with summary of variables for test set -> check out why we are off in which prediction
test_red %>%
  group_by("Borough" = borough) %>%
  summarize("AVG Crimes per Month" = round(sum(crimes) / n_distinct(month)),
            "Households" = unique(household),
            "Population Density" = unique(population_density),
            "Average Age" = unique(avg_age),
            "Employment Rate Male" = unique(employment_rate_male_2015)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```

&nbsp;

```{r lm faceted charts, include=TRUE, echo=FALSE, fig.width=6.5, fig.height=3.5, fig.align='left'}
# faceted line chart with all boroughs and prediction 0
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_lm0, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. LM Prediction 0",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 1
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_lm1, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  geom_line(show.legend = FALSE, size = 1) +
  labs(title = "Reported Crimes vs. LM Prediction 1",
       x = "Month", y = "Number of Crimes")


# faceted line chart with all boroughs and prediction 2
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_lm2, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. LM Prediction 2",
       x = "Month", y = "Number of Crimes")


# faceted line chart with all boroughs and prediction 3
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_lm3, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. LM Prediction 3",
       x = "Month", y = "Number of Crimes")


# faceted line chart with all boroughs and prediction 4
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_lm4, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. LM Prediction 4",
       x = "Month", y = "Number of Crimes")

```


&nbsp;



## K-Nearest Neighbours Algorithm

The third method we are going to try is the K-Nearest Neighbours Algorithm. We will use the ```train()``` function in R, as we can simultaneously train and tune our model with this function. By default the ```train()``` function performs coss-validation by testing on 25 bootstrap samples comprised of 25% of the observations and also tries k = 5, 7 and 9 for ```method = "knn"``` (source: PH125.8x Machine Learning). 

However, we don't just want to try these three values for k, we will set a different range of k's the function should try. When k = 1 the estimate for each (${x}_{1}$, ${x}_{2}$) in the training set is obtained with just the ${y}$ corresponding to that point. That would lead to very high accuracy in the train set, but also means we are over-training. On the other hand we can get over-smoothing if we select a k so large that we include very far away neighbours, which means we don't permit enough flexibility (source: PH125.8x Machine Learning). 
Our dataset is relatively small, so we won't get an issue with computational power and can try a larger range of k's, as long as we keep in mind that we want to prevent both over-trainig and  over-smoothing. I've defined a sequence from 1 to 100 with increments of 1 to try out for tuning. 

&nbsp;

```{r fit knn0, include=TRUE, echo=TRUE, fig.width=5, fig.height=3.5}
# fit knn to predict crimes and simultaneously tuning k
fit_knn0 <- train(crimes ~ month, method = "knn", data = train_red,
                  tuneGrid = data.frame(k = seq(1, 100, 1)))

# check which k is the best tune
fit_knn0$bestTune
fit_knn0$finalModel

ggplot(fit_knn0, highlight = TRUE)     

# predict crimes for the test data
predicted_crimes_knn0 <- predict(fit_knn0, test_red)

# evaluate the prediction 
rmse_knn0 <- RMSE(reported_crimes, predicted_crimes_knn0)

```

&nbsp;
 
The chart above shows that the best tune for k is `r fit_knn0$bestTune`. However, the largest gains are achieved in the range between about 12 and 30, as the descent of the RMSE is the steepest in this area. 
Similar to the LM prediction, we also train the KNN-models in four additional versions subsequently adding household, population density, average age and employment rate male. 
The results are displayed in the table below. The KNN predictions with more than just month as regressor perform relatively well compared to our starting point of the overall average, but the LM model with month, households and population density is still by far the best model until now.


```{r fit other knn predictions, include=TRUE, echo=FALSE}
# predict crimes for the other possible knn models
fit_knn1 <- train(crimes ~ month + household, 
                  method = "knn", data = train_red, tuneGrid = data.frame(k = seq(1, 100, 1)))
fit_knn2 <- train(crimes ~ month + household + population_density, 
                  method = "knn", data = train_red, tuneGrid = data.frame(k = seq(1, 100, 1)))
fit_knn3 <- train(crimes ~ month + household + population_density + avg_age, 
                  method = "knn", data = train_red, tuneGrid = data.frame(k = seq(1, 100, 1)))
fit_knn4 <- train(crimes ~ month + household + population_density + avg_age + 
                    employment_rate_male_2015, 
                  method = "knn", data = train_red, tuneGrid = data.frame(k = seq(1, 100, 1)))

predicted_crimes_knn1 <- predict(fit_knn1, newdata = test_red)
predicted_crimes_knn2 <- predict(fit_knn2, newdata = test_red)
predicted_crimes_knn3 <- predict(fit_knn3, newdata = test_red)
predicted_crimes_knn4 <- predict(fit_knn4, newdata = test_red)

rmse_knn1 <- RMSE(reported_crimes, predicted_crimes_knn1)
rmse_knn2 <- RMSE(reported_crimes, predicted_crimes_knn2)
rmse_knn3 <- RMSE(reported_crimes, predicted_crimes_knn3)
rmse_knn4 <- RMSE(reported_crimes, predicted_crimes_knn4)

# store the prediction results in a table
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = c("KNN month", 
                                            "KNN month+households", 
                                            "KNN month+households+density", 
                                            "KNN month+households+density+age",
                                            "KNN month+households+density+age+employment"), 
                                 RMSE = c(round(rmse_knn0), round(rmse_knn1), round(rmse_knn2),
                                          round(rmse_knn3), round(rmse_knn4))))

rmse_results %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```


```{r knn chart prep, include=FALSE, echo=FALSE}
# charts comparing reported crimes and predictions for the different knn models

predicted_crimes_knn0 <- as_tibble(predicted_crimes_knn0)
predicted_crimes_knn0 <- predicted_crimes_knn0 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_knn1 <- as_tibble(predicted_crimes_knn1)
predicted_crimes_knn1 <- predicted_crimes_knn1 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_knn2 <- as_tibble(predicted_crimes_knn2)
predicted_crimes_knn2 <- predicted_crimes_knn2 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_knn3 <- as_tibble(predicted_crimes_knn3)
predicted_crimes_knn3 <- predicted_crimes_knn3 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_knn4 <- as_tibble(predicted_crimes_knn4)
predicted_crimes_knn4 <- predicted_crimes_knn4 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

```

Looking at the charts below we can see that the KNN prediction is not a straight line like the LM prediction, but varies a bit during the year due to the weak seasonality that is given in each time series. Prediction 0 is worst for Harrow, Lambeth and Sutton, whereas the other four models all perform pretty well for Barnet, Bromley, Harrow and Sutton, but are relatively far off for Havering and Lambeth.

```{r knn faceted charts, include=TRUE, echo=FALSE, fig.width=6.5, fig.height=3.5, fig.align='left'}
# faceted line chart with all boroughs and prediction 0
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_knn0, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. KNN Prediction 0",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 1
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_knn1, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  geom_line(show.legend = FALSE, size = 1) +
  labs(title = "Reported Crimes vs. KNN Prediction 1",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 2
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_knn2, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. KNN Prediction 2",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 3
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_knn3, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. KNN Prediction 3",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 4
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_knn4, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. KNN Prediction 4",
       x = "Month", y = "Number of Crimes")

```

&nbsp;



## Regression Tree (rpart)

The last method we will try is a Regression Tree using the ```rpart``` package in R. Regression Trees or Decision Trees (for categorical outcomes) "build a decision tree and, at the end of each node, obtain a predictor $\hat{y}$. Mathematically, we are partitioning the predictor space into $J$ non-overlapping regions, $R_1, R_2,... , R_J$ and then for any predictor $x$ that falls within region $R_j$, estimate $f(x)$ with the average of the training observations $y_i$ for which the associated predictor $x_i$ is also in $R_j$. To pick $j$ and its value $s$, we find the pair that minimizes the residual sum of squares (RSS)" (source: PH125.8x Machine Learning).

The ```rpart``` package defines two tuning parameters, cp which is the complexity parameter and minsplit which represents the minimum number of observations that are required in a partition in order to further partition it. The complexity parameter cp can be understood as the "minimum benefit" that an additional partition must add to the decision tree. ```Rpart()``` only partitions if the split adds at least this much benefit. If cp = 0 there are no restrictions to the paritioning, so the function will compute the most complex tree possible.
In our case the dataset is relatively small and as stated above we shouldn't run into any issues due to a lack of computational power, so we can risk allowing the most complex tree possible. The selected range for the cp is 0 to 0.10. 

&nbsp;

```{r fit rpart0, include=TRUE, echo=TRUE, fig.width=5, fig.height=3.5, warning=FALSE}
# fit rpart to predict crimes and simultaneously tune cp
fit_rpart0 <- train(crimes ~ month, 
                    method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.10, len = 50)), 
                    data = train_red)

# tuning: look at the RMSE for the different cp
ggplot(fit_rpart0, highlight = TRUE)

# predict crimes in the test set
predicted_crimes_rpart0 <- predict(fit_rpart0, newdata = test_red)

# evaluate prediction for the test set
rmse_rpart0 <- RMSE(reported_crimes, predicted_crimes_rpart0)

```

&nbsp;

Again we train the other four model variations as well. The table below shows the results. Two of the Regression Tree models actually beat our best LM model. Due to the very good results of the Rpart prediction 2 and 4 I've also tried another version to see whether this further improves the prediction. The Rpart prediction 5 is a combination of rpart 2 and 4, using month + households + population density + employment rate male. Unfortunately the combined model performs worse than the single ones.

```{r other rpart predictions, include=FALSE, echo=FALSE}
# predict crimes for the other possible rpart models
fit_rpart1 <- train(crimes ~ month + household, 
                    method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.10, len = 50)), 
                    data = train_red)
fit_rpart2 <- train(crimes ~ month + household + population_density, 
                    method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.10, len = 50)), 
                    data = train_red)
fit_rpart3 <- train(crimes ~ month + household + population_density + avg_age, 
                    method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.10, len = 50)), 
                    data = train_red)
fit_rpart4 <- train(crimes ~ month + household + population_density + avg_age +
                      employment_rate_male_2015, 
                    method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.10, len = 50)), 
                    data = train_red)

predicted_crimes_rpart1 <- predict(fit_rpart1, newdata = test_red)
predicted_crimes_rpart2 <- predict(fit_rpart2, newdata = test_red)
predicted_crimes_rpart3 <- predict(fit_rpart3, newdata = test_red)
predicted_crimes_rpart4 <- predict(fit_rpart4, newdata = test_red)

rmse_rpart1 <- RMSE(reported_crimes, predicted_crimes_rpart1)
rmse_rpart2 <- RMSE(reported_crimes, predicted_crimes_rpart2)
rmse_rpart3 <- RMSE(reported_crimes, predicted_crimes_rpart3)
rmse_rpart4 <- RMSE(reported_crimes, predicted_crimes_rpart4)

# store the prediction results in a table
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = c("RPart month", 
                                            "RPart month+households", 
                                            "RPart month+households+density", 
                                            "RPart month+households+density+age",
                                            "RPart month+households+density+age+employment"), 
                                 RMSE = c(round(rmse_rpart0), round(rmse_rpart1),
                                          round(rmse_rpart2), round(rmse_rpart3), 
                                          round(rmse_rpart4))))

rmse_results %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)
```


```{r fit extra rpart5, include=TRUE, echo=FALSE}
# due to the very good rmse results of models rpart3 and rpart5 we try another model to check
# whether we can further improve the results with this combination
fit_rpart5 <- train(crimes ~ month + household + population_density + employment_rate_male_2015, 
                    method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.10, len = 50)), 
                    data = train_red)
predicted_crimes_rpart5 <- predict(fit_rpart5, newdata = test_red)

rmse_rpart5 <- RMSE(reported_crimes, predicted_crimes_rpart5)

# store the prediction results in a table
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = c("RPart month+households+density+employment"), 
                                 RMSE = c(round(rmse_rpart5))))

rmse_results %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped"),
                position = "center",
                font_size = 9,
                full_width = FALSE)

```


```{r rpart chart prep, include=TRUE, echo=FALSE}
# charts comparing reported crimes and predictions for the different rpart models
predicted_crimes_rpart0 <- as_tibble(predicted_crimes_rpart0)
predicted_crimes_rpart0 <- predicted_crimes_rpart0 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_rpart1 <- as_tibble(predicted_crimes_rpart1)
predicted_crimes_rpart1 <- predicted_crimes_rpart1 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_rpart2 <- as_tibble(predicted_crimes_rpart2)
predicted_crimes_rpart2 <- predicted_crimes_rpart2 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_rpart3 <- as_tibble(predicted_crimes_rpart3)
predicted_crimes_rpart3 <- predicted_crimes_rpart3 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_rpart4 <- as_tibble(predicted_crimes_rpart4)
predicted_crimes_rpart4 <- predicted_crimes_rpart4 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

predicted_crimes_rpart5 <- as_tibble(predicted_crimes_rpart5)
predicted_crimes_rpart5 <- predicted_crimes_rpart5 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)

```


The charts again reveal that prediction 0 is worst for Harrow, Lambeth and Sutton. Prediction 1, in contrast, is farthest off for Havering and Lambeth. Prediction 3 failed so much for Barnet, Bromley and Havering that we even needed to enlarge the y-axis. Prediction 2 and 4, however, are a pretty close fit. 


```{r rpart faceted charts, include=TRUE, echo=FALSE, fig.width=6.5, fig.height=3.5, fig.align='left'}
# faceted line chart with all boroughs and prediction 0
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_rpart0, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 0",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 1
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_rpart1, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  geom_line(show.legend = FALSE, size = 1) +
  labs(title = "Reported Crimes vs. RPart Prediction 1",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 2
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_rpart2, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 2",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 3 (larger y axis for this chart!)
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 5000) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_rpart3, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 3",
       subtitle = "(different y-axis than other charts!)",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 4
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_rpart4, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 4",
       x = "Month", y = "Number of Crimes")

# faceted line chart with all boroughs and prediction 5
test_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_rpart5, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 5",
       x = "Month", y = "Number of Crimes")

```

&nbsp;


**Results of the Model Development** 

In this chapter we have explored several different prediction models, starting with the simple Average and Linear Regression. Then we moved on to two more sophisticated methods with K-Nearest Neighbours and a Regression Tree. For all except the simple Average we have actually trained five different models. Several of the models performed well. The chart below illustrates the RMSE results of all models and highlights the best performing one: the Rpart Regression Tree with variables month + households + population density. In second place is the Rpart Regression Tree with variables month + households + population density + average age + employment rate male. The third best performing model was the Linear Regression with variables month + households + population density.

```{r RMSE chart, include=TRUE, echo=FALSE, fig.width=10, fig.height=6}
# chart comparing the RMSE for the different models on the test set
rmse_results %>%
  ggplot(aes(Method, RMSE, fill = ifelse(Method == "RPart month+households+density", "A", "B"))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_manual(values = c(A = "steelblue2", B = "grey95")) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 55, vjust = 1, hjust = 1)) +
  labs(title = "RMSE Results for the Different Models",
       x = "", y = "RMSE")
```



\newpage

# Results on the Validation Dataset

Now that we have identified our final model, we can evaluate the model performance on an unseen dataset, which is our validation dataset. In order to use as much training data as possible, we combine the original train and test sets to a new "enlarged" train dataset. This does not represent over-training, as we are not going to use the validation dataset for any model selection or tuning tasks. All we are achieving with this step is that we give our selected model with the selected best tune as much trainig data as possible, which hopefully improves performance on any unseen dataset. By combining the original train and test set, we give the model 27 boroughs to train on instead of the 21.

&nbsp;

```{r train enlarged, include=FALSE, echo=FALSE}
# combine train and test dataset
train_red_enlarged <- full_join(train_red, test_red) 

```


```{r data prep validation, include=FALSE, echo=FALSE}
# get the validation dataset into the same reduced structure as the train_red and test_red sets
validation_red <- validation %>%
  group_by(month, borough) %>%
  summarize(crimes = sum(value), household = unique(household), 
            population_density = unique(population_density), 
            avg_age = unique(avg_age),
            employment_rate_male_2015 = unique(employment_rate_male_2015)) %>%
  select(month, borough, crimes, household, population_density, 
         avg_age, employment_rate_male_2015)

# put together the reported crimes vector to evaluate against based on the validation dataset
reported_crimes_val <- validation %>%
  group_by(month, borough) %>%
  summarise(crimes = sum(value))

reported_crimes_val <- reported_crimes_val %>%
  .$crimes

# get the auxiliary month and borough columns
month_col <- validation_red %>%
  .$month 
borough_col <- validation_red %>%
  .$borough

```


```{r fit validation, include=TRUE, echo=TRUE}
# fit the rpart model 
# (using the rpart function instead of the train function, as we don't want to do any tuning, 
# which the train function always includes, but use the best tune from rpart3)
fit_val_rpart3 <- rpart(crimes ~ month + household + population_density, 
                        data = train_red_enlarged, 
                        control = rpart.control(cp = fit_rpart3$bestTune))

# predict crimes in the validation set
predicted_crimes_val_rpart3 <- predict(fit_val_rpart3, newdata = validation_red)

# evaluate prediction for the validation set
rmse_val_rpart3 <- RMSE(reported_crimes_val, predicted_crimes_val_rpart3)
round(rmse_val_rpart3)

```

&nbsp;

With almost 500 the RMSE for the prediction of the validation set is definitely not as good as the prediction of the test set. However, this was to be expected, as we selected the best performing model for the test set. The chart below shows that the prediction is especially bad for the borough City of London. This borough is somewhat of an outlier as it has only about 10-30 crimes per month. 

&nbsp;


```{r validation faceted chart, include=TRUE, echo=FALSE, fig.width=6.5, fig.height=3.5, fig.align='left'}
# preparation for the chart
predicted_crimes_val_rpart3 <- as_tibble(predicted_crimes_val_rpart3)
predicted_crimes_val_rpart3 <- predicted_crimes_val_rpart3 %>%
  mutate(month = month_col, borough = borough_col, crimes = value)


# faceted line chart with all boroughs and prediction for validation dataset
validation_red %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
#  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_val_rpart3, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 3 - Validation Dataset",
       x = "Month", y = "Number of Crimes")

```



```{r fit validation without CoL, include=FALSE, echo=FALSE, fig.width=6.5, fig.height=3.5, fig.align='left'}
# same prediction, but without City of London
validation_red_noCoL <- validation %>%
  filter(borough != "City of London") %>%
  group_by(month, borough) %>%
  summarize(crimes = sum(value), household = unique(household), 
            population_density = unique(population_density), 
            avg_age = unique(avg_age),
            employment_rate_male_2015 = unique(employment_rate_male_2015)) %>%
  select(month, borough, crimes, household, population_density, 
         avg_age, employment_rate_male_2015)


# put together the reported crimes vector to evaluate against based on the validation dataset
reported_crimes_val_noCoL <- validation %>%
  filter(borough != "City of London") %>%
  group_by(month, borough) %>%
  summarise(crimes = sum(value))

reported_crimes_val_noCoL <- reported_crimes_val_noCoL %>%
  .$crimes

# get the auxiliary month and borough columns
month_col <- validation_red_noCoL %>%
  .$month 
borough_col <- validation_red_noCoL %>%
  .$borough



# fit the rpart model
fit_val_rpart3_noCoL <- rpart(crimes ~ month + household + population_density, 
                              data = train_red_enlarged, 
                              control = rpart.control(cp = fit_rpart3$bestTune))

# predict crimes in the validation set
predicted_crimes_val_rpart3_noCoL <- predict(fit_val_rpart3_noCoL, newdata = validation_red_noCoL)

# evaluate prediction for the validation set
rmse_val_rpart3_noCoL <- RMSE(reported_crimes_val_noCoL, predicted_crimes_val_rpart3_noCoL)


# preparation for the chart
predicted_crimes_val_rpart3_noCoL <- as_tibble(predicted_crimes_val_rpart3_noCoL)
predicted_crimes_val_rpart3_noCoL <- predicted_crimes_val_rpart3_noCoL %>%
  mutate(month = month_col, borough = borough_col, crimes = value)


# faceted line chart with all boroughs and prediction for validation dataset
validation_red_noCoL %>%
  group_by(month, borough) %>%
  ggplot(aes(month, crimes, color = borough)) +
  geom_line(show.legend = FALSE, size = 1) +
  ylim(0, 3400) +
  scale_x_continuous(breaks = c(1:12)) +
  geom_line(data = predicted_crimes_val_rpart3_noCoL, color = "darkgrey", show.legend = FALSE) +
  facet_wrap(~borough) +
  theme_minimal() +
  labs(title = "Reported Crimes vs. RPart Prediction 3 - Validation Dataset",
       x = "Month", y = "Number of Crimes")

```

If we do the same prediction again but without City of London, the performance is much better (RMSE: `r round(rmse_val_rpart3_noCoL)`). Naturally, we can't just drop one borough from our dataset because the prediction results are unsatisfactory. However, this result suggests that a further improvement of the prediction should be possible by forming a separate prediction for City of London, and potentially as well for Westminster. City of London has unusually low documented crimes and Westminster repeatedly turned up as an outlier during the exploratory data analysis. Maybe an approach with a combination of different forecasting methods could do more justice to those two boroughs. It would go beyond this project to add yet another prediction, but this could certainly be a starting point for future work.



\newpage

# Conclusion

Over the course of this project we have explored our dataset and throughly analyzed the different variables and their relationship with the number of crimes. The exploratory data analysis revealed that the number of crimes mostly varies depending on months, households, population density, average age and male employment rate. Using the insights from the EDA, we set out to predict the number of crimes for the boroughs in our test dataset. During model development we tried various different methods and model variations, ranging from the simple Average over Linear Regression to K-Nearest Neighbours and Regression Trees. The best performing model was the Regression Tree using the predictors month, households and population density which returned a final RMSE of `r round(rmse_val_rpart3)` on our validation dataset. 

However, predicting the crimes in our validation dataset revealed an issue: the borough City of London is an outlier for which the prediction is much worse than for the other boroughs. Addressing this issue should considerably improve the overall prediction results, as we have shown in the last chapter. Maybe an approach with a combination of different predictions for City of London and the other boroughs would do more justice to the differences. Another interesting extension - although not as promising as better accounting for the City of London - could be to try Random Forests. Random Forests address the shortcomings of Decision or Regression Trees, because they reduce instability by averaging multiple Trees. Basically, a Random Forest is "a forest of trees constructed with randomness" (source: PH125.8x Machine Learning). The Regression Tree was our best performing method, so further improving this approach could turn out to be beneficial. 





\newpage

# Appendix

**Environment**

```{r echo=FALSE}
print("Operating System:")
version
```
